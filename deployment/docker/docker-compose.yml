# Optimized Docker Compose for Container Analytics
# Uses BuildKit cache features and optimized build strategy

x-build-prod: &default-build-prod
  context: ../..
  dockerfile: deployment/docker/Dockerfile.prod
  cache_from:
    - type=registry,ref=container-analytics:cache
  args:
    BUILDKIT_INLINE_CACHE: 1

x-common-env: &common-env
  PYTHONUNBUFFERED: 1
  DATABASE_URL: sqlite:////data/database.db
  DOCKER_CONTAINER: true

x-healthcheck: &default-healthcheck
  interval: 2m
  timeout: 30s
  start_period: 1m
  retries: 3

services:
  # Image Download Scheduler Service
  scheduler:
    build: *default-build-prod
    container_name: container-analytics-scheduler
    restart: unless-stopped
    environment:
      <<: *common-env
      SERVICE_TYPE: scheduler
      DOWNLOAD_INTERVAL_MINUTES: ${DOWNLOAD_INTERVAL_MINUTES:-10}
      RETENTION_DAYS: ${RETENTION_DAYS:-30}
      STREAMS: ${STREAMS:-in_gate}
    volumes:
      - ../../data:/data
      - ../../logs:/logs
    healthcheck:
      <<: *default-healthcheck
      test: ["CMD", "python", "/app/health_check.py"]
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 2G
        reservations:
          cpus: '0.1'
          memory: 256M
    networks:
      - container-analytics
    depends_on:
      redis:
        condition: service_healthy

  # YOLO Detection Service
  detector:
    build: *default-build-prod
    container_name: container-analytics-detector
    restart: unless-stopped
    environment:
      <<: *common-env
      SERVICE_TYPE: detector
      YOLO_MODEL_PATH: /data/models/yolov8x.pt
    volumes:
      - ../../data:/data
      - ../../logs:/logs
    healthcheck:
      <<: *default-healthcheck
      test: ["CMD", "python", "/app/health_check.py"]
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
          # GPU support (uncomment if GPU available)
          # devices:
          #   - driver: nvidia
          #     count: 1
          #     capabilities: [gpu]
        reservations:
          cpus: '0.5'
          memory: 1G
    networks:
      - container-analytics
    depends_on:
      scheduler:
        condition: service_healthy
      redis:
        condition: service_healthy

  # Streamlit Dashboard Service
  dashboard:
    build: *default-build-prod
    container_name: container-analytics-dashboard
    restart: unless-stopped
    environment:
      <<: *common-env
      SERVICE_TYPE: dashboard
      STREAMLIT_PORT: 8501
    ports:
      - "${DASHBOARD_PORT:-8501}:8501"
    volumes:
      - ../../data:/data:ro  # Read-only for dashboard
      - ../../logs:/logs
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.2'
          memory: 512M
    networks:
      - container-analytics
    depends_on:
      scheduler:
        condition: service_started

  # Prometheus Metrics Service
  metrics:
    build: *default-build-prod
    container_name: container-analytics-metrics
    restart: unless-stopped
    environment:
      <<: *common-env
      SERVICE_TYPE: metrics
    ports:
      - "${METRICS_PORT:-9090}:9090"
    volumes:
      - ../../data:/data:ro
      - ../../logs:/logs
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    networks:
      - container-analytics
    profiles:
      - monitoring

  # Redis Cache Service
  redis:
    image: redis:7-alpine
    container_name: container-analytics-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 512M
        reservations:
          cpus: '0.05'
          memory: 64M
    networks:
      - container-analytics

  # NGINX Reverse Proxy (Optional)
  nginx:
    image: nginx:alpine
    container_name: container-analytics-nginx
    restart: unless-stopped
    ports:
      - "${HTTP_PORT:-80}:80"
      - "${HTTPS_PORT:-443}:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ../../logs/nginx:/var/log/nginx
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 128M
        reservations:
          cpus: '0.05'
          memory: 32M
    networks:
      - container-analytics
    depends_on:
      dashboard:
        condition: service_healthy
      metrics:
        condition: service_started
    profiles:
      - production  # Only start with --profile production

  # Log Aggregation (Optional)
  loki:
    image: grafana/loki:2.9.0
    container_name: container-analytics-loki
    restart: unless-stopped
    ports:
      - "3100:3100"
    volumes:
      - loki_data:/loki
      - ./loki/config.yml:/etc/loki/local-config.yaml:ro
    command: -config.file=/etc/loki/local-config.yaml
    healthcheck:
      test: ["CMD", "wget", "-q", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.1'
          memory: 256M
    networks:
      - container-analytics
    profiles:
      - monitoring  # Only start with --profile monitoring

  # Grafana Dashboard (Optional)
  grafana:
    image: grafana/grafana:10.1.0
    container_name: container-analytics-grafana
    restart: unless-stopped
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.1'
          memory: 256M
    networks:
      - container-analytics
    depends_on:
      metrics:
        condition: service_started
      loki:
        condition: service_started
    profiles:
      - monitoring  # Only start with --profile monitoring

volumes:
  redis_data:
    driver: local
  loki_data:
    driver: local
  grafana_data:
    driver: local

networks:
  container-analytics:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16